<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>&#1044;&#1072;&#1074;&#1072;&#1081;&#1090;&#1077; &#1085;&#1077; &#1089;&#1087;&#1072;&#1089;&#1072;&#1090;&#1100; Stack, &#1072; &#1084;&#1086;&#1076;&#1080;&#1092;&#1080;&#1094;&#1080;&#1088;&#1086;&#1074;&#1072;&#1090;&#1100; &#1077;&#1075;&#1086;! | RuSO Archive </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="&#1044;&#1072;&#1074;&#1072;&#1081;&#1090;&#1077; &#1085;&#1077; &#1089;&#1087;&#1072;&#1089;&#1072;&#1090;&#1100; Stack, &#1072; &#1084;&#1086;&#1076;&#1080;&#1092;&#1080;&#1094;&#1080;&#1088;&#1086;&#1074;&#1072;&#1090;&#1100; &#1077;&#1075;&#1086;! | RuSO Archive ">
    <meta name="generator" content="docfx 2.59.4.0">
    
    <link rel="shortcut icon" href="../../../../favicon.ico">
    <link rel="stylesheet" href="../../../../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../../../../styles/docfx.css">
    <link rel="stylesheet" href="../../../../styles/main.css">
    <meta property="docfx:navrel" content="../../../../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../../../../index.html">
                <img id="logo" class="svg" src="../../../../logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="">

<p><i><a href="https://github.com/MSDN-WhiteKnight/ruso-archive/">RuSO Archive</a></i></p>
<h1>Давайте не спасать Stack, а модифицировать его!</h1>
<p><a href="https://ru.meta.stackoverflow.com/questions/14645/%d0%94%d0%b0%d0%b2%d0%b0%d0%b9%d1%82%d0%b5-%d0%bd%d0%b5-%d1%81%d0%bf%d0%b0%d1%81%d0%b0%d1%82%d1%8c-stack-%d0%b0-%d0%bc%d0%be%d0%b4%d0%b8%d1%84%d0%b8%d1%86%d0%b8%d1%80%d0%be%d0%b2%d0%b0%d1%82%d1%8c-%d0%b5%d0%b3%d0%be">Source</a> - by <a href="https://ru.meta.stackoverflow.com/users/223583/yury-bakharev">Yury Bakharev</a></p>
<blockquote>
<p>В ввиду понятных событий связанных с LLM, предлагаю. На каждый вопрос сразу приводить ответы LLM(чем больше интеграций с разными системами, тем лучше), а уже сообщество может модерировать ответы, поправлять, утверждать, если лучше не скажешь. Сейчас запрос на валидность ответов от LLM очень высокий. &quot;Блокчейн&quot; стека никуда не делся, люди то остались, мы делали это раньше, можем сделать и сейчас. По поводу реализации можно рассмотреть массу возможностей. Кто жив, напишите что думаете по этому поводу!?</p>
</blockquote>
<h2>Answer 14646</h2>
<p><a href="https://ru.meta.stackoverflow.com/a/14646/">Source</a> - by <a href="https://ru.meta.stackoverflow.com/users/177188/kromster">Kromster</a></p>
<blockquote>
<h3>Плохая затея</h3>
<ol>
<li><p>В основной массе, ответы ChatGPT (и других LLM) всё еще недостаточно хороши. Они часто ошибаются и фантазируют то, чего, напрмиер, в языках просто нету.</p>
</li>
<li><p>При этом они выглядят достаточно убедительно для &quot;неэкспертов&quot;, чем вводят в заблуждение. LLM достаточно плохо справляются с тем, чтобы мотивировать и/или отстаивать свои ответы. То есть за ответом нету экспертного мнения - LLM ответит что угодно &quot;на отвали&quot;.</p>
</li>
<li><p>В то же время, они выглядят как лакомый кусок для новичков, чтобы нафармить репы (for the fun of it). Копируй да вставляй! Чем больше накопируешь, тем больше плюсов.</p>
</li>
<li><p>Глобально - это отравление колодца. LLM учится на SO. Если SO будет состоять из низкокачественного контента от LLM, то нас ждет рекурсивное и ухудшение качества.</p>
</li>
<li><p>SO не про отладку чужих домашек. SO нужны каноничные вопросы и ответы по конкретным уникальным проблемам. Использование копипасты с LLM недостаточно. Нужен механизм &quot;причесывания&quot; и вопросов тоже. Иначе см п.3</p>
</li>
<li><p><strong>StackOverflow нам не поможет</strong>. Это интересное обсуждение, но без модификации движка сайта (или без планов по созданию своего Хэшкода 2.0) это все пустой звук.</p>
</li>
</ol>
<p>Конечно можно сказать, что будет экспертная проверка, и будут размещаться только гарантированно-правильные ответы. Но в вашей идее не видно механизмов ведущих к этому. Наоборот, выглядит как карт-бланш  для копипастеров.</p>
<hr>
<p>Если бы ответы были достаточно хороши и проверялись экспертами - это бы могло сработать. Но в текущей ситуации, слишком много слабых звеньев - всё же нет.</p>
</blockquote>
<h2>Answer 14647</h2>
<p><a href="https://ru.meta.stackoverflow.com/a/14647/">Source</a> - by <a href="https://ru.meta.stackoverflow.com/users/264178/dev18">Dev18</a></p>
<blockquote>
<h3>Хорошая идея — если подойти с человеческим умом</h3>
<p>Большинство LLM-ответов действительно пока ещё не совсем идеальны. Но в этом и суть: использовать ИИ <strong>не как финальный ответ</strong>, а как <strong>инструмент поддержки</strong></p>
<hr>
<p><strong>1. Черновик и участие вместо тишины</strong>
Некоторые вопросы могут висеть неделями без ответов. LLM может дать стартовую версию — пусть даже неидеальную, но с явной пометкой “ответ от ИИ”. Это лучше, чем тишина: так появляется хотя бы отправная точка.</p>
<p>Кроме того, такие ответы становятся поводом включиться — особенно для тех, кто не готов писать с нуля, но может отредактировать, уточнить, указать на ошибку. Это как code review: ты не автор, но участвуешь — и учишься.</p>
<p>Если встроить это в систему — с маркировкой, фильтрацией, “песочницей”, ограниченным каналом публикации — получится не поток мусора, а прозрачный, управляемый процесс.
Можно даже представить “ИИ-сообщества” как персонажа (альтернатива “Духу сообщества”), от имени которого публикуются такие ответы. А участники, которые проверяют и дорабатывают, получают видимую роль и вклад</p>
<p><strong>2. Возможность на стеке посмотреть ответы разных моделей</strong>.
На стеке появится способ ответов на вопросы сгенерированные разными моделями, как у SO не спрашивали разрешение на то что его базу возьмут для обучения, так как и SO может поступить интегрируя в себя кучу разных моделей, параллельно составляя их рейтинг по каждой из тематик.</p>
<p><strong>3. Как вариант борьбы с ответами из LLM сейчас</strong>
Уйдут ответы тех кто пытается нажиться с помощью LLM, так как ответы уже будут представлены (либо духом, либо автоматически, это детали реализации), об этом же кричат модераторы которые разбирают сетки вопросов.</p>
<p><strong>4. Новый формат ответов</strong>
Появится возможность использовать силу комьюнити в оценки ответов LLM и это будет на SO. Люди будут знать, что этот ответ хоть кем-то валидирован и степень лояльности выше, это может (а может конечно и нет) придать новый импульс, почему нужно зайти на SO  посмотреть ответ там, а не просто в интерфейсе LLM. А также люди не имеющие доступа к моделям (по любым причинам), получат лишний повод посмотреть как они отвечали в уже имеющейся базе.</p>
<hr>
<p>ИИ — это реальность. Либо мы встроим его на своих условиях, либо он встроится сам — криво, как попало и кстати мы уже замечаем иногда посты от ИИ. Выбирать пока ещё можно</p>
</blockquote>
<h2>Answer 14649</h2>
<p><a href="https://ru.meta.stackoverflow.com/a/14649/">Source</a> - by <a href="https://ru.meta.stackoverflow.com/users/672540/ivan-shatsky">Ivan Shatsky</a></p>
<blockquote>
<p>Я выскажу несколько дополнительных мыслей как относительно исходного вопроса, так и относительно некоторых комментариев.</p>
<p>На данный момент мы и так уже практически все в той или иной степени пользуемся ИИ. На многие вопросы ИИ и так уже может дать достаточно грамотный ответ. Разработчики IDE интегрируют ИИ в свои продукты. С моей точки зрения, если человек, задавший вопрос на SO, не попытался предварительно воспользоваться помощью ИИ, то это даже немного странно. Так что при нынешней модели работы SO от этого будет один только вред, который в одном из предыдущих ответов достаточно метко обозвали &quot;отравлением колодца&quot;.</p>
<p>В каком случае нечто подобное могло бы принести реальную пользу? Если бы подобных механизм имел обратную связь с самой LLM. Например, человек задаёт вопрос, приводит ответ какой-то из моделей LLM на свой вопрос, и жалуется, что ответ от LLM не работает. При этом сам вопрос помимо &quot;тематических&quot; тэгов получает дополнительно ещё и так называемый LLM-тэг. На вопрос отвечают живые люди, автор вопроса, а так же остальные посетители голосуют за ответы в обычном режиме, наилучший ответ, который решил проблему, автор вопроса отмечает, как принятый, и так далее. А потом на сайт приходит бот от соответствующей LLM и использует всю эту накопившуюся информацию для дообучения своей модели.</p>
<p>Совместима ли подобная модель с текущим форматом сайта? Не думаю. Возможно, для чего-то подобного можно было бы создать совершенно отдельный раздел, но этот вопрос уже будет затрагивать как минимум ещё и руководство StackOverflow. Будет ли оно заинтересовано в создании подобного раздела? С учётом того, что они вроде как развивают свою собственную модель, не уверен. Смогут ли соответствующие ИИ модели использовать такую информацию для максимально эффективного дообучения? Наверное только если их боты будут соответствующим образом доработаны своими разработчиками.</p>
<p>На всякий случай приведу один интересный скриншот из своей переписки с ChatGPT:</p>
<p><a href="https://i.sstatic.net/nuZnlSfP.png" rel="nofollow noreferrer"><img src="https://i.sstatic.net/nuZnlSfP.png" alt="Dialog with ChatGPT"></a></p>
<p>Для тех, кто не читает по английски, перевод:</p>
<blockquote>
<p>Я знаю, что вы тоже можете ошибаться. Недавно вы дали мне почти правильный, и тем не менее нерабочий ответ; я поправляю вас, говоря: &quot;Всё еще не работает; дальнейшее расследование показало, что значение переменной <code>reversed_hex</code> записано в нижнем регистре, а <code>bc</code> ожидает шестнадцатеричную строку в верхнем регистре&quot;, и ваш следующий исправленный ответ уже работает идеально. Учитываете ли вы такие исправления, и используете ли их в других чатах с другими людьми?</p>
<p>Отличный вопрос! На самом деле я не &quot;учусь&quot; на индивидуальных взаимодействиях таким образом, чтобы это изменило мои ответы для для других пользователей. Когда я делаю ошибки, а вы исправляете их в нашем разговоре, я корректирую свой ответ для этого сеанса, чтобы дать вам наилучший возможный ответ. Однако эти исправления специфичны для нашего чата и не обновляют автоматически то, как я отвечаю на подобные вопросы для других пользователей или в других сеансах.<br>
Когда улучшения вносятся в мою модель, они обычно основаны на более широких данных или конкретных обновлениях обучения от моих разработчиков в OpenAI, а не на исправлениях отдельных пользователей. Таким образом, любые ошибки, которые я здесь делаю, не будут напрямую влиять на ответы для других, но обратная связь, подобная вашей, может помочь команде OpenAI определить области, в которых модель может выиграть от улучшения. Спасибо, что работаете над этими исправлениями вместе со мной!</p>
</blockquote>
<p>И в заключение, приведу один из своих постов в переписке с автором одного из телеграм-каналов, связанных с определённой областью IT. В своём посте автор канала рассказывает о своём отношении об использовании ИИ в IT, а в конце интересуется, как относиться к тому, что в одном из ответов ИИ сослался на одну из его статей, и называет это &quot;воровством контента&quot;.</p>
<blockquote>
<p>У меня не такая узкая специализация, как у вас, мне часто приходится заниматься совершенно новыми для себя областями, и вот к какому выводу я пришёл.</p>
<p>Для старта в какой-то новой области ИИ исключительно хорош. Его можно попросить написать пример использования какой-то библиотеки или API, он его выдаст, его можно поизучать. Можно попросить его написать код для какой-то рутинной задачи, и с достаточно высокой вероятностью он выдаст что-то работоспособное. Но просить его написать что-то сложное в расчёте на то, что он сходу выдаст вам код, который можно будет использовать, в общем случае лишено смысла. И тем не менее, я достаточно часто прошу его это сделать. Мой подход к результату можно описать примерно так: внимательно изучи код, который выдал тебе ИИ, пойми, как он работает (ну или должен бы был работать), и напиши для решения задачи свой собственный. Не можешь разобраться в коде? Тогда не пользуйся для подобных задач ИИ вообще. Не можешь написать свой собственный код? Задумайся о смене профессии. Как-то так.</p>
<p>Ну и по поводу вопроса, как относиться к. Не претендую на звание специалиста в области машинного обучения, но в моём понимании, именно так и работают LLM. Результат их работы - это результат компиляции огромного количества входных данных, которые были созданы такими людьми, как вы (или я, хотя и в другой области IT). Я тоже иногда пытаюсь поделиться опытом с другими людьми. Как сказал один человек, между словами &quot;я читал туториалы&quot; и &quot;я их писал&quot; огромная пропасть. Я бы порадовался, что именно мой, а не чей-то другой текст был использован для генерации результата. Увы, вы тоже наверное знаете, что в сети огромное количество безграмотных туториалов и хаутушек, которые, к сожалению, влияют на качество ответов ИИ, по крайней мере на данном этапе развития этой технологии. А вообще надо учесть, что скорее всего мы сейчас наблюдаем самые начальные этапы её развития, и мало кто может предсказать, что она будет представлять из себя лет этак через 10. Пока что у меня нет опасений насчёт того, что ИИ действительно заменит <em>грамотных</em> IT-специалистов. Но это только пока, посмотрим, что будет дальше.</p>
</blockquote>
</blockquote>
<hr>
<p><i>Content is retrieved from StackExchange API. </i></p>
<p><i>Auto-generated by ruso-archive tools. </i></p>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
                <h5>In This Article</h5>
                <div></div>
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            <span>RuSO Archive (published from sources in <a href="https://github.com/MSDN-WhiteKnight/ruso-archive">GitHub repository</a>). Content licensed under <a href="https://github.com/MSDN-WhiteKnight/ruso-archive/blob/master/LICENSE">CC-BY-SA 4.0</a>.<br>Generated by <strong>DocFX</strong></span>
            
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../../../../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../../../../styles/docfx.js"></script>
    <script type="text/javascript" src="../../../../styles/main.js"></script>
  </body>
</html>

{"owner":{"reputation":28844,"user_id":176051,"user_type":"registered","accept_rate":80,"profile_image":"https://i.stack.imgur.com/mXEYl.png?s=128&g=1","display_name":"Kyubey","link":"https://ru.stackoverflow.com/users/176051/kyubey"},"is_accepted":true,"score":122,"last_activity_date":1430472763,"creation_date":1430472763,"answer_id":420355,"question_id":420354,"body":"<p>Регулярные выражения предназначены для обработки относительно простых текстов, которые задаются <a href=\"https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D1%8B%D0%B9_%D1%8F%D0%B7%D1%8B%D0%BA\">регулярными языками</a>. Регулярные выражения со времени своего появления сильно усложнились, особенно в Perl, реализация регулярных выражений в котором является вдохновением для остальных языков и библиотек, но регулярные выражения всё ещё плохо приспособлены (и вряд ли когда-либо будут) для обработки сложных языков типа HTML. Сложность обработки HTML заключается ещё и в очень сложных правилах обработки невалидного кода, которые достались по наследству от первых реализаций времён рождения Интернета, когда никаких стандартов не было и в помине, а каждый производитель браузеров нагромождал уникальные и неповторимые возможности.</p>\n\n<p>Итак, в общем случае регулярные выражения — не лучший кандидат для обработки HTML. Обычно разумнее использовать специализированные парсеры HTML.</p>\n\n<h1><a href=\"https://github.com/jamietre/CsQuery\">CsQuery</a></h1>\n\n<p>Лицензия: MIT</p>\n\n<p>Один из современных парсеров HTML для .NET. В качестве основы взят парсер validator.nu для Java, который в свою очередь является портом парсера из движка Gecko (Firefox). Это гарантирует, что парсер будет обрабатывать код точно так же, как современные браузеры.</p>\n\n<p>API черпает вдохновение у jQuery, для выбора элементов используется язык селекторов CSS. Названия методов скопированы практически один-в-один, то есть для программистов, знакомых с jQuery, изучение будет простым.</p>\n\n<p>Обладает высокой производительностью. На порядки превосходит HtmlAgilityPack+Fizzler по скорости на сложных запросах.</p>\n\n<pre><code>CQ cq = CQ.Create(html);\nforeach (IDomObject obj in cq.Find(\"a\"))\n    Console.WriteLine(obj.GetAttribute(\"href\"));\n</code></pre>\n\n<p>Если требуется более сложный запрос, то код практически не усложняется:</p>\n\n<pre><code>CQ cq = CQ.Create(html);\nforeach (IDomObject obj in cq.Find(\"h3.r a\"))\n    Console.WriteLine(obj.GetAttribute(\"href\"));\n</code></pre>\n\n<h1><a href=\"https://htmlagilitypack.codeplex.com/\">HtmlAgilityPack</a></h1>\n\n<p>Лицензия: Ms-PL</p>\n\n<p>Самый старый, и потому самый популярный парсер для .NET. Однако возраст не означает качество, например, уже пять лет (!!!) висит незакрытым критический баг <a href=\"https://htmlagilitypack.codeplex.com/workitem/29218\">Incorrect parsing of HTML4 optional end tags</a>, который приводит к некорректной обработке тегов HTML, закрывающие теги для которых опциональны. В API присутствуют странности, например, если ничего не найдено, возвращается <code>null</code>, а не пустая коллекция.</p>\n\n<p>Для выбора элементов используется язык XPath, а не селекторы CSS. На простых запросах код получается более-менее удобочитаемый:</p>\n\n<pre><code>HtmlDocument hap = new HtmlDocument();\nhap.LoadHtml(html);\nHtmlNodeCollection nodes = hap.DocumentNode.SelectNodes(\"//a\");\nif (nodes != null)\n    foreach (HtmlNode node in nodes)\n        Console.WriteLine(node.GetAttributeValue(\"href\", null));\n</code></pre>\n\n<p>Однако если нужны сложные запросы, то XPath оказывается не очень приспособленным для имитации CSS селекторов:</p>\n\n<pre><code>HtmlDocument hap = new HtmlDocument();\nhap.LoadHtml(html);\nHtmlNodeCollection nodes = hap.DocumentNode.SelectNodes(\n    \"//h3[contains(concat(' ', @class, ' '), ' r ')]/a\");\nif (nodes != null)\n    foreach (HtmlNode node in nodes)\n        Console.WriteLine(node.GetAttributeValue(\"href\", null));\n</code></pre>\n\n<h1><a href=\"https://code.google.com/p/fizzler/\">Fizzler</a></h1>\n\n<p>Лицензия: LGPL</p>\n\n<p>Надстройка к HtmlAgilityPack, позволяющая использовать селекторы CSS.</p>\n\n<pre><code>HtmlDocument hap = new HtmlDocument();\nhap.LoadHtml(html);\nforeach (HtmlNode node in hap.DocumentNode.QuerySelectorAll(\"h3.r a\"))\n    Console.WriteLine(node.GetAttributeValue(\"href\", null));\n</code></pre>\n\n<h1><a href=\"https://github.com/FlorianRappl/AngleSharp\">AngleSharp</a></h1>\n\n<p>Лицензия: BSD (3-clause)</p>\n\n<p>Новый игрок на поле парсеров. В отличие от CsQuery, написан с нуля вручную на C#. Также включает парсеры других языков.</p>\n\n<p>API построен на базе официальной спецификации по JavaScript HTML DOM. В некоторых местах есть странности, непривычные для разработчиков на .NET (например, при обращении к неверному индексу в коллекции будет возвращён <code>null</code>, а не выброшено исключение; есть свой отдельный класс <code>Url</code>; пространства имён очень гранулярные, даже базовое использование библиотеки требует три <code>using</code> и т. п.), но в целом ничего критичного.</p>\n\n<p>Из других странностей — библиотека тащит за собой Microsoft BCL Portability Pack. Поэтому, когда подключите AngleSharp через NuGet, не удивляйтесь, если обнаружите подключенными три дополнительных пакета: Microsoft.Bcl, Microsoft.Bcl.Build, Microsoft.Bcl.Async.</p>\n\n<p>Обработка HTML простая:</p>\n\n<pre><code>IHtmlDocument angle = new HtmlParser(html).Parse();\nforeach (IElement element in angle.QuerySelectorAll(\"a\"))\n    Console.WriteLine(element.GetAttribute(\"href\"));\n</code></pre>\n\n<p>Она не усложняется, и если нужна более сложная логика:</p>\n\n<pre><code>IHtmlDocument angle = new HtmlParser(html).Parse();\nforeach (IElement element in angle.QuerySelectorAll(\"h3.r a\"))\n    Console.WriteLine(element.GetAttribute(\"href\"));\n</code></pre>\n\n<h1><a href=\"https://msdn.microsoft.com/library/hs600312.aspx\">Regex</a></h1>\n\n<p>Страшные и ужасные регулярные выражения. Применять их нежелательно, но иногда возникает необходимость, так как парсеры, которые строят DOM, заметно прожорливее, чем <code>Regex</code>: они потребляют больше и процессорного времени, и памяти.</p>\n\n<p>Если дошло до регулярных выражений, то нужно понимать, что вы не сможете построить на них универсальное и абсолютно надёжное решение. Однако если вы хотите парсить конкретный сайт, то эта проблема может быть не так критична.</p>\n\n<p>Ради всего святого, не надо превращать регулярные выражения в нечитаемое месиво. Вы не пишете код на C# в одну строчку с однобуквенными именами переменных, так и регулярные выражения не нужно портить. Движок регулярных выражений в .NET достаточно мощный, чтобы можно было писать качественный код.</p>\n\n<p>Например, вот немного доработанный код для извлечения ссылок из вопроса:</p>\n\n<pre><code>Regex reHref = new Regex(@\"(?inx)\n    &lt;a \\s [^&gt;]*\n        href \\s* = \\s*\n            (?&lt;q&gt; ['\"\"] )\n                (?&lt;url&gt; [^\"\"]+ )\n            \\k&lt;q&gt;\n    [^&gt;]* &gt;\");\nforeach (Match match in reHref.Matches(html))\n    Console.WriteLine(match.Groups[\"url\"].ToString());\n</code></pre>\n"}